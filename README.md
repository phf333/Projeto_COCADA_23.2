# Classifica√ß√£o de Imagens de Animais utilizando TensorFlow

## Paulo Henrique de Fran√ßa Araujo Cunha

Este projeto tem como objetivo criar um algoritmo com boas m√©tricas para classificar animais em fotos retiradas da internet. Utilizaremos bibliotecas em Python, como TensorFlow, Matplotlib, Numpy, entre outras, para alcan√ßar nosso objetivo.

Os principais passos para atingir o objetivo final s√£o:

1. Encontrar um dataset
2. Preparar o dataset
3. Modelar a rede neural
4. Compilar
5. Treinar
6. Verificar resultados
7. Testar

# Introdu√ß√£o

As fotos s√£o dados presentes em nossas vidas. Diariamente, gostamos de tirar fotos de animais bonitinhos, c√©us bonitos ou do nosso cotidiano. Pensando nisso, surgiu a ideia de explorar o reconhecimento de imagens e entender como funciona o treinamento de uma rede neural. Para isso, decidi cavar um pouco nesse problema de reconhecimento de animais em fotos.

# Ferramentas B√°sicas

- **Python:** Linguagem de programa√ß√£o utilizada no desenvolvimento do projeto.
- **TensorFlow:** Biblioteca de c√≥digo aberto para aprendizado de m√°quina.
- **Numpy:** Biblioteca poderosa para trabalhar com processamento de dados, vetores e matrizes.
- **Matplotlib:** Biblioteca para plotar gr√°ficos e visualizar dados.

# Metodologia

Retornaremos aos passos definidos anteriormente para alcan√ßar o objetivo final de classificar novas imagens de animais.

###  _Utilize o c√≥digo em python disponibilizado nesse mesmo reposit√≥rio para melhorar seu passo a passo._

## 1. Encontrar um dataset

Escolhi o dataset do Kaggle chamado **Animal Image Dataset (90 Different Animals)**. O dataset cont√©m 90 tipos diferentes de animais.

![Alt text](imagens/image.png)

## 2. Preparar o dataset

A prepara√ß√£o do dataset envolve a declara√ß√£o de vari√°veis e a divis√£o das pastas/imagens em grupos de treinamento e valida√ß√£o. Para normalizar o problema, todas as imagens foram redimensionadas para 180x180. O dataset foi dividido em 80% para treinamento e 20% para valida√ß√£o.

As 90 classes presentes no dataset s√£o:

```python
['antelope', 'badger', 'bat', 'bear', 'bee', 'beetle', 'bison', 'boar', 'butterfly', 'cat', 'caterpillar', 'chimpanzee', 'cockroach', 'cow', 'coyote', 'crab', 'crow', 'deer', 'dog', 'dolphin', 'donkey', 'dragonfly', 'duck', 'eagle', 'elephant', 'flamingo', 'fly', 'fox', 'goat', 'goldfish', 'goose', 'gorilla', 'grasshopper', 'hamster', 'hare', 'hedgehog', 'hippopotamus', 'hornbill', 'horse', 'hummingbird', 'hyena', 'jellyfish', 'kangaroo', 'koala', 'ladybugs', 'leopard', 'lion', 'lizard', 'lobster', 'mosquito', 'moth', 'mouse', 'octopus', 'okapi', 'orangutan', 'otter', 'owl', 'ox', 'oyster', 'panda', 'parrot', 'pelecaniformes', 'penguin', 'pig', 'pigeon', 'porcupine', 'possum', 'raccoon', 'rat', 'reindeer', 'rhinoceros', 'sandpiper', 'seahorse', 'seal', 'shark', 'sheep', 'snake', 'sparrow', 'squid', 'squirrel', 'starfish', 'swan', 'tiger', 'turkey', 'turtle', 'whale', 'wolf', 'wombat', 'woodpecker', 'zebra']
```

## 3. Modelagem da rede neural

Optei por uma rede neural sequencial para este problema. O modelo √© simples, composto por camadas convolucionais, de pooling, flatten e densas.

```python
model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
```

## 4. Compilar

Ap√≥s a modelagem, o modelo √© compilado para prepar√°-lo para o treinamento.

```python
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

### 5. Treinar

Com o modelo compilado, o treinamento da rede neural √© realizado. Neste caso, foram utilizadas 10 √©pocas.

![Alt text](imagens/image-2.png)

### 6. Verificar Resultados

Durante a realiza√ß√£o do projeto eu realizei 4 testes, e os resultados obtidos foram analisados para identificar poss√≠veis melhorias no modelo.

## Primeiro Resultado

![Alt text](imagens/image-3.png)

Ao analisar o primeiro resultado, vemos que a porcentagem de treinamento chegou a quase 100%, enquanto a de valida√ß√£o n√£o seguiu o mesmo caminho e ficou muito abaixo, cerca de 40%. Isso indica um sinal de overfitting no nosso modelo, que √© exatamente quando o modelo n√£o consegue prever bem as imagens de teste com o que foi treinado.
Dessa forma √© preciso encontrarmos maneiras de melhor√°-lo.

A primeira ideia foi de usar tecnicas de aumento do dataset, ou seja, talvez por meu dataset n√£o ter um tamanho suficientemente grande(5400 imagens), ele esteja tendo dificuldade de treinar o modelo. Dessa forma, iremos usar fun√ß√µes existentes no tensorflow, que a partir das imagens do pr√≥prio dataset, s√£o criadas novas com pequenas varia√ß√µes.

-Girando no eixo horizontal<br>
-Girando 10%<br>
-Dando zoom de 10%<br>

E eu criei uma fun√ß√£o que fazia todas essas aplica√ß√µes de uma vez e coloquei no modelo para o segundo teste.

![Alt text](imagens/image-4.png)

## Segundo Resultado

![Alt text](imagens/image-5.png)

Ao rodarmos o segundo teste, era esperado que o modelo tivesse uma melhora, visto que aumentamos o nosso dataset e colocamos mais epocas pra ele treinar(15). Todavia, n√£o foi o observado. N√£o entendi muito o que houve nesse caso, mas fui aplicar um terceiro teste, pensando que talvez o numero de √©pocas tenha sido baixo. Dessa forma, rodei o pr√≥ximo teste com 30.

## Terceiro Resultado

![Alt text](imagens/image-6.png)

Que resultado! ü§°

N√£o tivemos praticamente nenhuma melhora, o modelo conseguiu apenas melhorar sua precis√£o de treinamento, mas sua valida√ß√£o foi muito abaixo do esperado.
Minha conclus√£o foi de que mesmo aumentando o numero de imagens e aumentando o numero de √©pocas, a quantidade de imagem passadas para um treinamento do zero era muito baixa.

## Quarto Resultado

Para esse quarto teste, eu precisei utilizar uma outra abordagem, pois as anteriores estavam muito ruins e n√£o parecia que ia melhorar. Foi ent√£o que com algumas pesquisas, descobri que poderia utilizar como base um modelo j√° treinado. Assim, pesquisei e encontrei um modelo que era bastante usado em problemas de classifica√ß√£o, e resolvi testar no meu projeto, o _MobileNetV2_ , apliquei ele na modelagem da rede neural, removi as camadas de treinamento do zero que estavam sendo usadas antes pelos testes anteriores, e mantive o aumento do dataset(com as tecnicas mencionadas no final do primeiro resultado), compilei e treinei com 20 √©pocas, obtive o seguinte resultado:

![Alt text](imagens/image-7.png)

Finalmente um resultado √≥timo! üòç

Conseguimos uma porcentagem de valida√ß√£o satisfat√≥ria de aproximadamente 84% e que dessa forma, poder√≠amos utilizar o modelo para prever novas imagens.

### 6. Testar

Por fim, com o modelo nas m√£os, resta pegar novas imagens e verificar se conseguimos umas previs√µes corretas.

Utilizei as seguintes imagens para previs√£o:

![Alt text](imagens/image-8.png)

E obtive os seguintes resultados:

```
1/1 [==============================] - 0s 22ms/step
Nome da Imagem:  cao4.webp
Para a imagem cao4.webp: Pertence a dog com 99.93% de confian√ßa.


1/1 [==============================] - 0s 20ms/step
Nome da Imagem:  rato.jpg
Para a imagem rato.jpg: Pertence a hamster com 98.39% de confian√ßa.


1/1 [==============================] - 0s 21ms/step
Nome da Imagem:  papa.jpeg
Para a imagem papa.jpeg: Pertence a parrot com 100.00% de confian√ßa.


1/1 [==============================] - 0s 21ms/step
Nome da Imagem:  cao1.jpg
Para a imagem cao1.jpg: Pertence a bee com 53.61% de confian√ßa.


1/1 [==============================] - 0s 24ms/step
Nome da Imagem:  cao3.jpg
Para a imagem cao3.jpg: Pertence a ox com 73.61% de confian√ßa.


1/1 [==============================] - 0s 21ms/step
Nome da Imagem:  rapo.jpg
Para a imagem rapo.jpg: Pertence a fox com 97.55% de confian√ßa.


1/1 [==============================] - 0s 20ms/step
Nome da Imagem:  cobra.jpg
Para a imagem cobra.jpg: Pertence a gorilla com 53.84% de confian√ßa.


1/1 [==============================] - 0s 28ms/step
Nome da Imagem:  cao2.jpg
Para a imagem cao2.jpg: Pertence a dog com 99.66% de confian√ßa.


1/1 [==============================] - 0s 22ms/step
Nome da Imagem:  elefa.jpg
Para a imagem elefa.jpg: Pertence a elephant com 96.38% de confian√ßa.
```

Tive algumas anormalidades, como uma cobra ser confundida com um gorilla, ou ent√£o um cachorro ser confundido com uma abelha. Mas no geral, tivemos uma boa porcertagem de acerto, mais que 50%.

# Conclus√£o

Criar modelos de classifica√ß√£o simples como esse possuem um passo a passo tranquilo de se fazer, mas √© preciso estar atento a pequenas caracteristicas importantes, quanto maior seu dataset, maior a chance de ter um bom modelo, mas √© preciso perceber tamb√©m as caracteristicas do seu problema, para pode escolher bem a modelagem da sua rede neural e do processo de compila√ß√£o. 

Caso voc√™ queira testar, pode usar o c√≥digo presente nesse reposit√≥rio. Basta alterar com seus dados e informa√ß√µes.

Obrigado üëå <br>

## Refer√™ncias

- [TensorFlow - Classifica√ß√£o de Imagens](https://www.tensorflow.org/tutorials/images/classification?hl=pt-br)
- [TensorFlow - Data Augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=pt-br)
- [Google Machine Learning Glossary](https://developers.google.com/machine-learning/glossary?hl=pt-br#dropout_regularization)
- [Underfitting e Overfitting](https://didatica.tech/underfitting-e-overfitting/)
- [TensorFlow - Sequential Model](https://www.tensorflow.org/guide/keras/sequential_model?hl=pt-br)
